<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <meta charset="utf-8">
    <title></title>
    <!-- Bootstrap 4 classes -->
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css">
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.16.0/umd/popper.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js"></script>

<link href="https://cdn.rawgit.com/michalsnik/aos/2.1.1/dist/aos.css" rel="stylesheet">
<script src="https://cdn.rawgit.com/michalsnik/aos/2.1.1/dist/aos.js"></script>

<link rel="stylesheet" href="animate.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.7.2/animate.min.css">
<link rel="stylesheet" href="bower_components/aos/dist/aos.css">
<link href="https://fonts.googleapis.com/css?family=Baskervville&display=swap" rel="stylesheet">
 <link href="https://fonts.googleapis.com/css?family=Merriweather:400i&display=swap" rel="stylesheet">
<script src="bower_components/aos/dist/aos.js"></script>
<!--   -->
<style media="screen">
  body{
    background: url("domainbg.png") no-repeat fixed center center;
    background-size:cover;
  }
  h1{
    font-size:60px;
    color:black;

  }
  ul {
  display: block;
  list-style-type: circle;
  margin-bottom: 1 em;
  margin-left: 0;
  margin-right: 0;
  text-align:left;
  font-size:20px;
}

  .jum{
    background-color:white;
    border-radius: 4px;
    opacity: 0.8;
    padding:30px;
  }
  .column{
    background-color:white;
    border-radius: 10px;
    opacity: 0.8;
  }
  p{
    color:black;
    opacity:none;
    font-size:20px;
    padding:10px;
    text-align: justify;
  }
  b{
    text-align:center;
  }
</style>
<script type="text/javascript">
  AOS.init();
</script>
  </head>
  <body>
    <nav class="fixed-top navbar navbar-expand-lg navbar-dark bg-secondary">
      <div class="navbar-brand">TechLens </div>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>

      <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <ul class="navbar-nav mr-auto">
          <li class="nav-item active">
            <a class="nav-link" href="index.html">Home <span class="sr-only">(current)</span></a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="domain.html">Domain</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="tech.html">Technology</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="contact.html">Contact</a>
          </li>

        </ul>

      </div>
    </nav>
    <div class="section"><br><br><br><br></div>


    <div class="section"> <br><br> </div>
    <div class="container-fluid">

      <center>
        <div class="col-md-10">
          <div class="jumbotron jum">
            <h1 class="text-center">Augumented Reality</h1>
          </div>
          <div class="row">
            <div class="col-md-12 column">
              <h3 style="font-size:40px;padding:10px;" class="text-center">ABOUT</h3>
              <p><b>Augmented reality (AR)</b> is an interactive experience of a real-world environment where the objects that reside in the real world are enhanced by computer-generated perceptual information, sometimes across multiple sensory modalities, including visual, auditory, haptic, somatosensory and olfactory.[1][2] An augogram is a computer generated image that is used to create AR. Augography is the science and practice of making augograms for AR. AR can be defined as a system that fulfills three basic features: a combination of real and virtual worlds, real-time interaction, and accurate 3D registration of virtual and real objects.[3] The overlaid sensory information can be constructive (i.e. additive to the natural environment), or destructive (i.e. masking of the natural environment).[4] This experience is seamlessly interwoven with the physical world such that it is perceived as an immersive aspect of the real environment.[4] In this way, augmented reality alters one's ongoing perception of a real-world environment, whereas virtual reality completely replaces the user's real-world environment with a simulated one.[5][6] Augmented reality is related to two largely synonymous terms: mixed reality and computer-mediated reality.
<br>
The primary value of augmented reality is the manner in which components of the digital world blend into a person's perception of the real world, not as a simple display of data, but through the integration of immersive sensations, which are perceived as natural parts of an environment. The earliest functional AR systems that provided immersive mixed reality experiences for users were invented in the early 1990s, starting with the Virtual Fixtures system developed at the U.S. Air Force's Armstrong Laboratory in 1992.[4][7][8] Commercial augmented reality experiences were first introduced in entertainment and gaming businesses. Subsequently, augmented reality applications have spanned commercial industries such as education, communications, medicine, and entertainment. In education, content may be accessed by scanning or viewing an image with a mobile device or by using markerless AR techniques.[9][10] An example relevant to the construction industry is an AR helmet for construction workers which displays information about construction sites.<br>

Augmented reality is used to enhance natural environments or situations and offer perceptually enriched experiences. With the help of advanced AR technologies (e.g. adding computer vision, incorporating AR cameras into smartphone applications and object recognition) the information about the surrounding real world of the user becomes interactive and digitally manipulated. Information about the environment and its objects is overlaid on the real world. This information can be virtual[11][12][13][14] or real, e.g. seeing other real sensed or measured information such as electromagnetic radio waves overlaid in exact alignment with where they actually are in space.[15][16][17] Augmented reality also has a lot of potential in the gathering and sharing of tacit knowledge. Augmentation techniques are typically performed in real time and in semantic contexts with environmental elements. Immersive perceptual information is sometimes combined with supplemental information like scores over a live video feed of a sporting event. This combines the benefits of both augmented reality technology and heads up display technology (HUD).<br>
<br><b>The difference between Virtual Reality & Augmented Reality</b> <br>
In Virtual Reality (VR), the users' perception of reality is completely based on virtual information. In Augmented Reality (AR) the user is provided with additional computer generated information that enhances their perception of reality.[18][19] For example, in architecture, VR can be used to create a walk-through simulation of the inside of a new building; and AR can be used to show a building's structures and systems super-imposed on a real-life view. Another example is through the use of utility applications. Some AR applications, such as Augment, enable users to apply digital objects into real environments, allowing businesses to use augmented reality devices as a way to preview their products in the real world.[20] Similarly, it can also be used to demo what products may look like in an environment for customers, as demonstrated by companies such as Mountain Equipment Co-op or Lowe's who use augmented reality to allow customers to preview what their products might look like at home through the use of 3D models.[21]
<br>
Augmented Reality (AR) differs from Virtual Reality (VR) in the sense that in AR part of the surrounding environment is actually 'real' and just adding layers of virtual objects to the real environment. On the other hand, in VR the surrounding environment is completely virtual. A demonstration of how AR layers objects onto the real world can be seen with augmented reality games. WallaMe is an augmented reality game application that allows users to hide messages in real environments, utilizing geolocation technology in order to enable users to hide messages wherever they may wish in the world.[22] Such applications have many uses in the world, including in activism and artistic expression.<br>
<br>
<br><b>Technology</b><br>
Photograph of man waearing smartglasses <br>
Man wearing smartglasses <br>
<br><b>Hardware <br></b>
Hardware components for augmented reality are: a processor, display, sensors and input devices. Modern mobile computing devices like smartphones and tablet computers contain these elements, which often include a camera and Microelectromechanical systems (MEMS) sensors such as an accelerometer, GPS, and solid state compass, making them suitable AR platforms.[24] There are two technologies used in augmented reality: diffractive waveguides and reflective waveguides.

<br><b>Display</b><br>
Various technologies are used in augmented reality rendering, including optical projection systems, monitors, handheld devices, and display systems, which are worn on the human body.
<br>
A head-mounted display (HMD) is a display device worn on the forehead, such as a harness or helmet-mounted. HMDs place images of both the physical world and virtual objects over the user's field of view. Modern HMDs often employ sensors for six degrees of freedom monitoring that allow the system to align virtual information to the physical world and adjust accordingly with the user's head movements.[25][26][27] HMDs can provide VR users with mobile and collaborative experiences.[28] Specific providers, such as uSens and Gestigon, include gesture controls for full virtual immersion.[29][30]
<br>
<br><b>Eyeglasses </b><br>
AR displays can be rendered on devices resembling eyeglasses. Versions include eyewear that employs cameras to intercept the real world view and re-display its augmented view through the eyepieces[31] and devices in which the AR imagery is projected through or reflected off the surfaces of the eyewear lens pieces.[32][33][34]
<br>
HUDb <br>
Photograph of a Headset computer <br>
Headset computer <br>
Main article: Head-up display <br>
A head-up display (HUD) is a transparent display that presents data without requiring users to look away from their usual viewpoints. A precursor technology to augmented reality, heads-up displays were first developed for pilots in the 1950s, projecting simple flight data into their line of sight, thereby enabling them to keep their "heads up" and not look down at the instruments. Near-eye augmented reality devices can be used as portable head-up displays as they can show data, information, and images while the user views the real world. Many definitions of augmented reality only define it as overlaying the information.[35][36] This is basically what a head-up display does; however, practically speaking, augmented reality is expected to include registration and tracking between the superimposed perceptions, sensations, information, data, and images and some portion of the real world.[37]
<br>
<br><b>Contact lenses <br></b>
Contact lenses that display AR imaging are in development. These bionic contact lenses might contain the elements for display embedded into the lens including integrated circuitry, LEDs and an antenna for wireless communication. The first contact lens display was reported in 1999,[38] then 11 years later in 2010-2011.[39][40][41][42] Another version of contact lenses, in development for the U.S. military, is designed to function with AR spectacles, allowing soldiers to focus on close-to-the-eye AR images on the spectacles and distant real world objects at the same time.[43][44]
<br>
The futuristic short film Sight[45] features contact lens-like augmented reality devices.[46][47]
<br>
Many scientists have been working on contact lenses capable of different technological feats. A patent filed by Samsung describes an AR contact lens, that, when finished, will include a built-in camera on the lens itself.[48] The design is intended to control its interface by blinking an eye. It is also intended to be linked with the user's smartphone to review footage, and control it separately. When successful, the lens would feature a camera, or sensor inside of it. It is said that it could be anything from a light sensor, to a temperature sensor.
<br>
In Augmented Reality, the distinction is made between two distinct modes of tracking, known as marker and markerless. Markers are visual cues which trigger the display of the virtual information.[49] A piece of paper with some distinct geometries can be used. The camera recognizes the geometries by identifying specific points in the drawing. Markerless tracking, also called instant tracking, does not use markers. Instead, the user positions the object in the camera view preferably in a horizontal plane. It uses sensors in mobile devices to accurately detect the real-world environment, such as the locations of walls and points of intersection.[50]
<br>
<br><b>Virtual retinal display</b> <br>
A virtual retinal display (VRD) is a personal display device under development at the University of Washington's Human Interface Technology Laboratory under Dr. Thomas A. Furness III.[51] With this technology, a display is scanned directly onto the retina of a viewer's eye. This results in bright images with high resolution and high contrast. The viewer sees what appears to be a conventional display floating in space.[52]
<br>
Several of tests were done to analyze the safety of the VRD.[51] In one test, patients with partial loss of vision—having either macular degeneration (a disease that degenerates the retina) or keratoconus—were selected to view images using the technology. In the macular degeneration group, five out of eight subjects preferred the VRD images to the cathode-ray tube (CRT) or paper images and thought they were better and brighter and were able to see equal or better resolution levels. The Keratoconus patients could all resolve smaller lines in several line tests using the VRD as opposed to their own correction. They also found the VRD images to be easier to view and sharper. As a result of these several tests, virtual retinal display is considered safe technology.
<br>
Virtual retinal display creates images that can be seen in ambient daylight and ambient room light. The VRD is considered a preferred candidate to use in a surgical display due to its combination of high resolution and high contrast and brightness. Additional tests show high potential for VRD to be used as a display technology for patients that have low vision.
<br>
<br><b>EyeTap <br></b>
The EyeTap (also known as Generation-2 Glass[53]) captures rays of light that would otherwise pass through the center of the lens of the wearer's eye, and substitutes synthetic computer-controlled light for each ray of real light.
<br>
The Generation-4 Glass[53] (Laser EyeTap) is similar to the VRD (i.e. it uses a computer-controlled laser light source) except that it also has infinite depth of focus and causes the eye itself to, in effect, function as both a camera and a display by way of exact alignment with the eye and resynthesis (in laser light) of rays of light entering the eye.[54]
<br>
<br><b>Handheld </b><br>
A Handheld display employs a small display that fits in a user's hand. All handheld AR solutions to date opt for video see-through. Initially handheld AR employed fiducial markers,[55] and later GPS units and MEMS sensors such as digital compasses and six degrees of freedom accelerometer–gyroscope. Today Simultaneous localization and mapping (SLAM) markerless trackers such as PTAM (parallel tracking and mapping) are starting to come into use. Handheld display AR promises to be the first commercial success for AR technologies. The two main advantages of handheld AR are the portable nature of handheld devices and the ubiquitous nature of camera phones. The disadvantages are the physical constraints of the user having to hold the handheld device out in front of them at all times, as well as the distorting effect of classically wide-angled mobile phone cameras when compared to the real world as viewed through the eye.[56]
<br>
Games such as Pokémon Go and Ingress utilize an Image Linked Map (ILM) interface, where approved geotagged locations appear on a stylized map for the user to interact with.[57]
<br>
<br><b>Networking <br></b>
Mobile augmented reality applications are gaining popularity because of the wide adoption of mobile and especially wearable devices. However, they often rely on computationally intensive computer vision algorithms with extreme latency requirements. To compensate for the lack of computing power, offloading data processing to a distant machine is often desired. Computation offloading introduces new constraints in applications, especially in terms of latency and bandwidth. Although there are a plethora of real-time multimedia transport protocols, there is a need for support from network infrastructure as well.[64]
<br>
<br><b>Input devices</b><br>
Techniques include speech recognition systems that translate a user's spoken words into computer instructions, and gesture recognition systems that interpret a user's body movements by visual detection or from sensors embedded in a peripheral device such as a wand, stylus, pointer, glove or other body wear.[65][66][67][68] Products which are trying to serve as a controller of AR headsets include Wave by Seebright Inc. and Nimble by Intugine Technologies.
<br>
<br><b>Computer <br></b>
The computer analyzes the sensed visual and other data to synthesize and position augmentations. Computers are responsible for the graphics that go with augmented reality. Augmented reality uses a computer-generated image which has a striking effect on the way the real world is shown. With the improvement of technology and computers, augmented reality is going to lead to a drastic change on ones perspective of the real world.[69] According to Time, in about 15–20 years it is predicted that augmented reality and virtual reality are going to become the primary use for computer interactions.[70] Computers are improving at a very fast rate, leading to new ways to improve other technology. The more that computers progress, augmented reality will become more flexible and more common in society. Computers are the core of augmented reality. [71] The computer receives data from the sensors which determine the relative position of an objects' surface. This translates to an input to the computer which then outputs to the users by adding something that would otherwise not be there. The computer comprises memory and a processor.[72] The computer takes the scanned environment then generates images or a video and puts it on the receiver for the observer to see. The fixed marks on an object's surface are stored in the memory of a computer. The computer also withdraws from its memory to present images realistically to the onlooker. The best example of this is of the Pepsi Max AR Bus Shelter.
<br>

<br><b>Projector <br></b>
Projectors can also be used to display AR contents. The projector can throw a virtual object on a projection screen and the viewer can interact with this virtual object. Projection surfaces can be many objects such as walls or glass panes.[74]
<br>
<br><b>Software and algorithms</b> <br>
art
A key measure of AR systems is how realistically they integrate augmentations with the real world. The software must derive real world coordinates, independent of camera, and camera images. That process is called image registration, and uses different methods of computer vision, mostly related to video tracking.[75][76] Many computer vision methods of augmented reality are inherited from visual odometry.
<br>
Usually those methods consist of two parts. The first stage is to detect interest points, fiducial markers or optical flow in the camera images. This step can use feature detection methods like corner detection, blob detection, edge detection or thresholding, and other image processing methods.[77][78] The second stage restores a real world coordinate system from the data obtained in the first stage. Some methods assume objects with known geometry (or fiducial markers) are present in the scene. In some of those cases the scene 3D structure should be calculated beforehand. If part of the scene is unknown simultaneous localization and mapping (SLAM) can map relative positions. If no information about scene geometry is available, structure from motion methods like bundle adjustment are used. Mathematical methods used in the second stage include: projective (epipolar) geometry, geometric algebra, rotation representation with exponential map, kalman and particle filters, nonlinear optimization, robust statistics.[citation needed]
<br>
Augmented Reality Markup Language (ARML) is a data standard developed within the Open Geospatial Consortium (OGC),[79] which consists of Extensible Markup Language (XML) grammar to describe the location and appearance of virtual objects in the scene, as well as ECMAScript bindings to allow dynamic access to properties of virtual objects.
<br>
To enable rapid development of augmented reality applications, some software development kits (SDKs) have emerged.[80][81]
<br>
<br><b>Development </b><br>
The implementation of augmented reality in consumer products requires considering the design of the applications and the related constraints of the technology platform. Since AR systems rely heavily on the immersion of the user and the interaction between the user and the system, design can facilitate the adoption of virtuality. For most augmented reality systems, a similar design guideline can be followed. The following lists some considerations for designing augmented reality applications:
<br>
<br><b>Environmental/context design </b><br>
Context Design focuses on the end-user's physical surrounding, spatial space, and accessibility that may play a role when using the AR system. Designers should be aware of the possible physical scenarios the end-user may be in such as:
<br>
Public, in which the users use their whole body to interact with the software <br>
Personal, in which the user uses a smartphone in a public space <br>
Intimate, in which the user is sitting with a desktop and is not really moving <br>
Private, in which the user has on a wearable. <br>
By evaluating each physical scenario, potential safety hazards can be avoided and changes can be made to greater improve the end-user's immersion. UX designers will have to define user journeys for the relevant physical scenarios and define how the interface reacts to each.
<br>
Especially in AR systems, it is vital to also consider the spatial and surrounding elements that change the effectiveness of the AR technology. Environmental elements such as lighting and sound can prevent the AR device sensor from detecting necessary data and ruin the immersion of the end-user.[83]
<br>
Another aspect of context design involves the design of the system's functionality and its ability to accommodate user preferences.[84][85] While accessibility tools are common in basic application design, some consideration should be made when designing time-limited prompts (to prevent unintentional operations), audio cues and overall engagement time. It is important to note that in some situations, the application's functionality may hinder the user's ability. For example, applications that is used for driving should reduce the amount of user interaction and use audio cues instead.
<br>
<b><br>Interaction design</b><br>
Interaction design in augmented reality technology centers on the user's engagement with the end product to improve the overall user experience and enjoyment. The purpose of interaction design is to avoid alienating or confusing the user by organizing the information presented. Since user interaction relies on the user's input, designers must make system controls easier to understand and accessible. A common technique to improve usability for augmented reality applications is by discovering the frequently accessed areas in the device's touch display and design the application to match those areas of control.[86] It is also important to structure the user journey maps and the flow of information presented which reduce the system's overall cognitive load and greatly improves the learning curve of the application.[87]
<br>
In interaction design, it is important for developers to utilize augmented reality technology that complement the system's function or purpose.[88] For instance, the utilization of exciting AR filters and the design of the unique sharing platform in Snapchat enables users to better the user's social interactions. In other applications that require users to understand the focus and intent, designers can employ a reticle or raycast from the device.[84] Moreover, augmented reality developers may find it appropriate to have digital elements scale or react to the direction of the camera and the context of objects that can are detected.[83]
<br>
Augmented reality technology allows to utilize the introduction of 3D space. This means that a user can potentially access multiple copies of 2D interfaces within a single AR application.[83]
<br>
<br><b>Visual design <br></b>
In general, visual design is the appearance of the developing application that engages the user. To improve the graphic interface elements and user interaction, developers may use visual cues to inform the user what elements of UI are designed to interact with and how to interact with them. Since navigating in an AR application may appear difficult and seem frustrating, visual cue design can make interactions seem more natural.[82]
<br>
In some augmented reality applications that use a 2D device as an interactive surface, the 2D control environment does not translate well in 3D space making users hesitant to explore their surroundings. To solve this issue, designers should apply visual cues to assist and encourage users to explore their surroundings.
<br>
It is important to note the two main objects in AR when developing VR applications: 3D volumetric objects that are manipulated and realistically interact with light and shadow; and animated media imagery such as images and videos which are mostly traditional 2D media rendered in a new context for augmented reality.[82] When virtual objects are projected onto a real environment, it is challenging for augmented reality application designers to ensure a perfectly seamless integration relative to the real-world environment, especially with 2D objects. As such, designers can add weight to objects, use depths maps, and choose different material properties that highlight the object's presence in the real world. Another visual design that can be applied is using different lighting techniques or casting shadows to improve overall depth judgment. For instance, a common lighting technique is simply placing a light source overhead at the 12 o’clock position, to create shadows on virtual objects.
</p></div></div>
        <div class="section"> <br><br><br> </div>
        <div class="row">
      <div class="col-md-5 column">
        <h3 style="font-size:40px;padding:10px;" class="text-center">References</h3>
        <ul>
          <li><a href="https://blog.viromedia.com/ar-101-learn-the-basics-of-augmented-reality-4b100e136242" target="_blank" >Viromedia</a></li>
          <li><a href="https://www.geeksforgeeks.org/virtual-reality-augmented-reality-and-mixed-reality/" target="_blank" >GeeksforGeeks</a></li>
        </ul>
    </div>
    <div class="section"> <br><br><br><br> </div>
    <div class="col-md-2"></div>
  <div class="col-md-5 column">
        <h3 style="font-size:40px;padding:10px;" class="text-center">Courses</h3>
        <ul>
          <li><a href="https://www.udemy.com/course/vuforia-image-target-tutorial/?utm_source=adwords&utm_medium=udemyads&utm_campaign=LongTail_la.EN_cc.INDIA&utm_content=deal4584&utm_term=_._ag_77882236463_._ad_387397828069_._kw__._de_c_._dm__._pl__._ti_dsa-1007766171312_._li_9062044_._pd__._&matchtype=b&gclid=Cj0KCQiAqNPyBRCjARIsAKA-WFyqEAbnnsdbJgIbrkbWRRhklwemo_l0bLTCtdyfg5DXCKuQiuvQJfAaAjulEALw_wcB" target="_blank" >Udemy</a></li>
          <li><a href="https://www.coursera.org/learn/augmented-reality" target="_blank" >Cousera</a></li>
        </ul>

      </div>
          </div>
        </div>
        </center>
    </div>
    <div class="section"> <br><br><br><br> </div>
  </body>
</html>
